{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e11bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from skimage import color, feature, exposure\n",
    "\n",
    "import random\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37daa6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_size = 300\n",
    "batch_size = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb85dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation is not applied for Test/Validation data\n",
    "transform_valid = transforms.Compose([\n",
    "    transforms.Resize((resize_size,resize_size)),\n",
    "    \n",
    "    transforms.ToTensor(),\n",
    "    #transforms.ToPILImage(), # the transform usually work with PIL images\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e4e1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = 'testdata'\n",
    "custom_dataset = ImageFolder(root=data_root, transform=transform_valid)\n",
    "\n",
    "# specify classes\n",
    "classes = ('cherry','strawberry', 'tomato')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9356464f",
   "metadata": {},
   "source": [
    "## 1. Load the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "108fe1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 32 * 32, 128)  # Adjust input size based on your images\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 3)# num_classes is the number of classes in your dataset\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)  # \"fc\" stands for fully connected, i.e. a nn.Linear layer\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f0bfa268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = './model.pth'\n",
    "\n",
    "model = nn.Sequential(\n",
    "    SimpleCNN(),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f348d8",
   "metadata": {},
   "source": [
    "## 2. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0df53327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on the test set\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "all_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "93b018b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7714dd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 35.33%\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy on the test set\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeb2f42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
